global:
  config_name: ecbp_hyperopt_clustering_xgboost


model:
  # Two options here:
  # (1) When running hyperparameter optimization for the mention pair classifier, this should be a string with the name
  #     of the classifier to optimize. Accepted values: SVC_huber, LR, XGBoost, MLP
  # (2) When running hyperparameter optimization for the clustering step, or when training the final model, this should
  #     be a dict with the type, args and kwargs necessary to instantiate the classifier.

  # following the results of 26414_2020-07-01_09-26-33
  classifier:
    type: ConvenientXGBClassifier
    fit_params:
        early_stopping_rounds: 5
        eval_metric: logloss
        validation_fraction: 0.1
        verbose: false
    kwargs:
        colsample_bylevel: 0.6487673032722361
        colsample_bytree: 0.6921908536463499
        eval_metric: logloss
        gamma: 0.3748321662847928
        learning_rate: 0.01567667719550607
        max_delta_step: 17.22894536960941
        max_depth: 6
        min_child_weight: 7.436704297351775
        n_estimators: 1000
        n_jobs: 1
        objective: 'binary:logistic'
        scale_pos_weight: 1.1394964521117115
        subsample: 0.8117818483929862

  features:
    # Extractors to use. If null, all extractors will be used with an exception: Extractors listed here which have no
    # feature selected below will not be instantiated.
    extractors:

    # Features of each extractor to use. If null, all features will be used.
    selected_features:
      # following the results of 26388_2020-06-30_17-06-31
      - lemma#is-surface-form-identical
      - lemma#is-lemma-identical
      - lemma#surface-form-mlinps-distance
      - lemma#surface-form-levenshtein-distance
      - tfidf#document-similarity
      - tfidf#surrounding-sentence-similarity
      - tfidf#context-similarity
      - sentence-embedding#doc-start
      - action-phrase-embedding#action-phrase

data:
  # paths to preprocessed pickle versions of datasets
  train_data_path: ""
  eval_data_path: ""

  # ECB+: gold topics, because topics were annotated individually
  doc_partitioning: "gold_topics"

  # if true, use gold labels for advanced mention pair generation
  oracle_mention_pair_generation: true

  pairs:
    # mention pair generator settings for training
    mpg_training:
      undersample_c: 8
      neg_to_pos_pair_ratio: 8

    # mention pair generator settings for predicting
    mpg_prediction:

hyperopt:
  with_clustering: true

  # how many repeats to use in repeated k-fold CV
  cv_num_repeats: 4

  # These have the same behaviour as reported here [1]. Timeout is parsed with pandas. Keep n_trials empty (== None)
  # and set timeout to try as many configs as possible in the given duration.
  # [1] https://optuna.readthedocs.io/en/latest/reference/study.html#optuna.study.Study.optimize
  n_trials:
  timeout: "22 hours"

  # This setting does unfortunately not work with parallelized optimization!
#  early_stopping:
#    patience: 30
#    min_delta: 0.001