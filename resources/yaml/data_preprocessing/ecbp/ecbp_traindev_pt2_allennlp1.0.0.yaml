global:
  config_name: preprocess_ECBP_traindev

pipeline:
  - python.handwritten_baseline.pipeline.data.loader.ecb_loader:
      path_to_data_split: "resources/data/ecbplus/train"
      sentence_filter_csv: "resources/data/ecbplus/ECBplus_coreference_sentences.csv"

  - python.handwritten_baseline.pipeline.data.loader.ecb_loader:
      path_to_data_split: "resources/data/ecbplus/valid"
      sentence_filter_csv: "resources/data/ecbplus/ECBplus_coreference_sentences.csv"

#  - python.handwritten_baseline.pipeline.data.processing.reducer:
#      num_topics: 8
#      num_docs_per_topic: 25

  - python.handwritten_baseline.pipeline.data.processing.corenlp_pos_ner:
      mode: extend

  - python.handwritten_baseline.pipeline.data.processing.timex_parse:

  - python.handwritten_baseline.pipeline.data.processing.entity_linking.dbpedia_spotlight:
      mode: extend

  - python.handwritten_baseline.pipeline.data.processing.entity_linking.location_enhance:

  - python.handwritten_baseline.pipeline.data.processing.srl:

#  - python.handwritten_baseline.pipeline.data.processing.masking:
#      event_components_to_mask: ["action", "participants", "time", "location"]

  - python.handwritten_baseline.pipeline.data.processing.feature_preparation.wikidata_embeddings:
      json_index: "resources/wikidata_embeddings/wikidata_translation_v1_names.json"
      embedding_npy: "resources/wikidata_embeddings/wikidata_translation_v1_vectors.npy"

  - python.handwritten_baseline.pipeline.data.processing.feature_preparation.sentence_bert_embeddings:
      pretrained_model_name: "distilbert-base-nli-stsb-mean-tokens"

  - python.handwritten_baseline.pipeline.data.processing.feature_preparation.action_phrase_embeddings:
      model: "resources/spanbert/model.tar.gz"

  - python.handwritten_baseline.pipeline.data.processing.dataset_exporter:
      dataset_name: ecbp
      split: traindev